{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "This dataset is hosted on kaggle, and there were some promising results posted there, but they werent properly verified. This is an endeavor to see what kind of results that the popular [deep learning notebook](https://www.kaggle.com/jacklinggu/keras-mlp-cnn-test-for-text-classification) would get if we used a balanced metric and an 80-20 train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T22:02:55.078534Z",
     "start_time": "2018-01-25T22:02:52.943418Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DT-Laptop\\Anaconda3\\envs\\new_ds\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import re\n",
    "from pprint import pprint\n",
    "from itertools import zip_longest\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "project_dir = Path.cwd().parent\n",
    "sys.path.append(str(project_dir/'src'))\n",
    "\n",
    "# These are utilities that I created to reduce notebook clutter\n",
    "from make_dataframe import make_dataframe, master_data_handler\n",
    "import utilities as ut\n",
    "import deep_learning as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T22:02:55.126065Z",
     "start_time": "2018-01-25T22:02:55.080533Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_data_handler()\n",
    "df = make_dataframe()\n",
    "df.label = df.label.map({'ham': 0, 'spam': 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T22:02:55.229973Z",
     "start_time": "2018-01-25T22:02:55.128066Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T22:02:55.354296Z",
     "start_time": "2018-01-25T22:02:55.231975Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, matthews_corrcoef\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T22:02:55.744709Z",
     "start_time": "2018-01-25T22:02:55.357300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 3. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]]\n",
      "(5572,) (5572, 1000)\n",
      "(5572, 1000)\n",
      "[49, 471, 842, 755, 658, 64, 8, 88, 123, 351, 148, 67, 58, 144]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  49 471 842 755\n",
      " 658  64   8  88 123 351 148  67  58 144]\n",
      "(5572, 100)\n"
     ]
    }
   ],
   "source": [
    "max_len = 100\n",
    "num_max = 1000\n",
    "tok = Tokenizer(num_words=num_max)\n",
    "tok.fit_on_texts(df.text)\n",
    "mat_texts = tok.texts_to_matrix(df.text, mode='count')\n",
    "print(df.label.shape,mat_texts.shape)\n",
    "\n",
    "cnn_texts_seq = tok.texts_to_sequences(df.text)\n",
    "cnn_texts_mat = sequence.pad_sequences(cnn_texts_seq,maxlen=max_len)\n",
    "print(cnn_texts_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T22:02:55.778738Z",
     "start_time": "2018-01-25T22:02:55.746210Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cnn_texts_mat, df.label, test_size=0.3, random_state=0)\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(mat_texts, df.label, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T22:03:15.676565Z",
     "start_time": "2018-01-25T22:02:55.780224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               512512    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 644,097\n",
      "Trainable params: 644,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "compile done\n",
      "Train on 3900 samples, validate on 1672 samples\n",
      "Epoch 1/10\n",
      "3900/3900 [==============================] - 3s 641us/step - loss: 0.1773 - acc: 0.9469 - binary_accuracy: 0.9469 - val_loss: 0.0664 - val_acc: 0.9844 - val_binary_accuracy: 0.9844\n",
      "Epoch 2/10\n",
      "3900/3900 [==============================] - 2s 521us/step - loss: 0.0305 - acc: 0.9936 - binary_accuracy: 0.9936 - val_loss: 0.0712 - val_acc: 0.9833 - val_binary_accuracy: 0.9833\n",
      "Epoch 3/10\n",
      "3900/3900 [==============================] - 2s 511us/step - loss: 0.0075 - acc: 0.9979 - binary_accuracy: 0.9979 - val_loss: 0.0762 - val_acc: 0.9850 - val_binary_accuracy: 0.9850\n",
      "Epoch 4/10\n",
      "3900/3900 [==============================] - 2s 444us/step - loss: 0.0038 - acc: 0.9990 - binary_accuracy: 0.9990 - val_loss: 0.0803 - val_acc: 0.9868 - val_binary_accuracy: 0.9868\n",
      "Epoch 5/10\n",
      "3900/3900 [==============================] - 2s 462us/step - loss: 0.0031 - acc: 0.9995 - binary_accuracy: 0.9995 - val_loss: 0.0949 - val_acc: 0.9868 - val_binary_accuracy: 0.9868\n",
      "Epoch 6/10\n",
      "3900/3900 [==============================] - 2s 481us/step - loss: 0.0021 - acc: 0.9997 - binary_accuracy: 0.9997 - val_loss: 0.0909 - val_acc: 0.9868 - val_binary_accuracy: 0.9868\n",
      "Epoch 7/10\n",
      "3900/3900 [==============================] - 2s 453us/step - loss: 0.0019 - acc: 0.9997 - binary_accuracy: 0.9997 - val_loss: 0.0954 - val_acc: 0.9862 - val_binary_accuracy: 0.9862\n",
      "Epoch 8/10\n",
      "3900/3900 [==============================] - 2s 461us/step - loss: 0.0018 - acc: 0.9997 - binary_accuracy: 0.9997 - val_loss: 0.0979 - val_acc: 0.9862 - val_binary_accuracy: 0.9862\n",
      "Epoch 9/10\n",
      "3900/3900 [==============================] - 2s 449us/step - loss: 0.0017 - acc: 0.9997 - binary_accuracy: 0.9997 - val_loss: 0.1006 - val_acc: 0.9856 - val_binary_accuracy: 0.9856\n",
      "Epoch 10/10\n",
      "3900/3900 [==============================] - 2s 475us/step - loss: 0.0015 - acc: 0.9997 - binary_accuracy: 0.9997 - val_loss: 0.1074 - val_acc: 0.9868 - val_binary_accuracy: 0.9868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('clf', <keras.wrappers.scikit_learn.KerasClassifier object at 0x000001F4442FA7B8>)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_dl_simple = Pipeline([\n",
    "    ('clf', KerasClassifier(build_fn=partial(dl.get_simple_model,num_max),\n",
    "                            batch_size=32,epochs=10,verbose=0, validation_split=.2,\n",
    "                            validation_data=(X_test_s, y_test_s))),\n",
    "])\n",
    "pipeline_dl_simple.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T22:03:15.829675Z",
     "start_time": "2018-01-25T22:03:15.682069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1672/1672 [==============================] - 0s 83us/step\n"
     ]
    }
   ],
   "source": [
    "y_true_s, y_pred_s = y_test_s, pipeline_dl_simple.predict(X_test_s)\n",
    "mcc_simp = matthews_corrcoef(y_true_s, y_pred_s)\n",
    "mcc_simp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T22:03:15.916786Z",
     "start_time": "2018-01-25T22:03:15.831175Z"
    }
   },
   "outputs": [],
   "source": [
    "def pipeline_dl(model_in, model_text, X_train, y_train, X_test, y_test, verbose=0):\n",
    "    pipeline_dl_v1 = Pipeline([\n",
    "        ('clf', KerasClassifier(build_fn=partial(model_in,num_max, max_len),\n",
    "                                batch_size=32,epochs=10,verbose=verbose, validation_split=.2,\n",
    "                                validation_data=(X_test, y_test))),\n",
    "    ])\n",
    "    pipeline_dl_v1.fit(X_train, y_train);\n",
    "\n",
    "    y_true, y_pred = y_test, pipeline_dl_v1.predict(X_test)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    print(f'------------------------------------------------------------')\n",
    "    print(f'{model_text} got an MCC of: {mcc}')\n",
    "    print(f'------------------------------------------------------------')\n",
    "    return mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T22:04:51.465189Z",
     "start_time": "2018-01-25T22:03:15.918794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 20)           20000     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 98, 64)            3904      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 40,801\n",
      "Trainable params: 40,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------\n",
      "Model V1 got an MCC of: 0.8949619135716199\n",
      "------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 50)           50000     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 98, 64)            9664      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 76,561\n",
      "Trainable params: 76,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------\n",
      "Model V2 got an MCC of: 0.9141356743368744\n",
      "------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 20)           20000     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 98, 256)           15616     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 101,665\n",
      "Trainable params: 101,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------\n",
      "Model V3 got an MCC of: 0.8815328957915707\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mcc_v1 = pipeline_dl(dl.get_cnn_model_v1, 'Model V1', X_train, y_train, X_test, y_test)\n",
    "mcc_v2 = pipeline_dl(dl.get_cnn_model_v2, 'Model V2', X_train, y_train, X_test, y_test)\n",
    "mcc_v3 = pipeline_dl(dl.get_cnn_model_v3, 'Model V3', X_train, y_train, X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T22:05:32.422276Z",
     "start_time": "2018-01-25T22:05:32.416782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple: 0.9417253825867283\n",
      "MCC V1: 0.8949619135716199\n",
      "MCC V2: 0.9141356743368744\n",
      "MCC V3: 0.8815328957915707\n"
     ]
    }
   ],
   "source": [
    "print(f'Simple: {mcc_simp}')\n",
    "print(f'MCC V1: {mcc_v1}')\n",
    "print(f'MCC V2: {mcc_v2}')\n",
    "print(f'MCC V3: {mcc_v3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
