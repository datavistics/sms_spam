{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "This dataset is hosted on kaggle, and there were some promising notebooks posted there, but they weren't properly verified. I will properly verify the results and compare to the work I have already done.This [deep learning notebook](https://www.kaggle.com/jacklinggu/keras-mlp-cnn-test-for-text-classification) in particular had strong results.\n",
    "\n",
    "Just to be clear, this is mostly not my work, but that of [Jackling_Gu](https://www.kaggle.com/jacklinggu). I have strong results and I want to see how I do against the best of Kaggle, and also see if there is room for growth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-26T05:10:26.592005Z",
     "start_time": "2018-01-26T05:10:24.585389Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DT-Laptop\\Anaconda3\\envs\\new_ds\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import re\n",
    "from pprint import pprint\n",
    "from itertools import zip_longest\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "project_dir = Path.cwd().parent\n",
    "sys.path.append(str(project_dir/'src'))\n",
    "\n",
    "# These are utilities that I created to reduce notebook clutter\n",
    "from make_dataframe import make_dataframe, master_data_handler\n",
    "import utilities as ut\n",
    "import deep_learning as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-26T05:10:26.622526Z",
     "start_time": "2018-01-26T05:10:26.593515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_data_handler()\n",
    "df = make_dataframe()\n",
    "df.label = df.label.map({'ham': 0, 'spam': 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-26T05:10:26.721302Z",
     "start_time": "2018-01-26T05:10:26.624028Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-26T05:10:26.859720Z",
     "start_time": "2018-01-26T05:10:26.722804Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, matthews_corrcoef\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Right now, keras does not allow custom tokenizers like sklearn does. In the future it would be good to write one from scratch and see if that could improve our results. I used just the basic split on whitespace for tokens.\n",
    "\n",
    "Unless expressly written, I left the code the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-26T05:10:27.242764Z",
     "start_time": "2018-01-26T05:10:26.861200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572,) (5572, 1000)\n",
      "(5572, 100)\n"
     ]
    }
   ],
   "source": [
    "max_len = 100\n",
    "num_max = 1000\n",
    "tok = Tokenizer(num_words=num_max)\n",
    "tok.fit_on_texts(df.text)\n",
    "mat_texts = tok.texts_to_matrix(df.text, mode='count')\n",
    "print(df.label.shape,mat_texts.shape)\n",
    "\n",
    "cnn_texts_seq = tok.texts_to_sequences(df.text)\n",
    "cnn_texts_mat = sequence.pad_sequences(cnn_texts_seq,maxlen=max_len)\n",
    "print(cnn_texts_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-26T05:10:27.270786Z",
     "start_time": "2018-01-26T05:10:27.244268Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cnn_texts_mat, df.label, test_size=0.3, random_state=0)\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(mat_texts, df.label, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-26T05:10:43.529071Z",
     "start_time": "2018-01-26T05:10:27.271785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               512512    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 644,097\n",
      "Trainable params: 644,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "compile done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('clf', <keras.wrappers.scikit_learn.KerasClassifier object at 0x0000019B3955A898>)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_dl_simple = Pipeline([\n",
    "    ('clf', KerasClassifier(build_fn=partial(dl.get_simple_model,num_max),\n",
    "                            batch_size=32,epochs=10,verbose=0, validation_split=.2,\n",
    "                            validation_data=(X_test_s, y_test_s))),\n",
    "])\n",
    "pipeline_dl_simple.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-26T05:10:43.638150Z",
     "start_time": "2018-01-26T05:10:43.531074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9391490788432957"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_s, y_pred_s = y_test_s, pipeline_dl_simple.predict(X_test_s)\n",
    "mcc_simp = matthews_corrcoef(y_true_s, y_pred_s)\n",
    "mcc_simp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-26T05:10:43.672083Z",
     "start_time": "2018-01-26T05:10:43.640651Z"
    }
   },
   "outputs": [],
   "source": [
    "def pipeline_dl(model_in, model_text, X_train, y_train, X_test, y_test, verbose=0):\n",
    "    pipeline_dl_v1 = Pipeline([\n",
    "        ('clf', KerasClassifier(build_fn=partial(model_in,num_max, max_len),\n",
    "                                batch_size=32,epochs=10,verbose=verbose, validation_split=.2,\n",
    "                                validation_data=(X_test, y_test))),\n",
    "    ])\n",
    "    pipeline_dl_v1.fit(X_train, y_train);\n",
    "\n",
    "    y_true, y_pred = y_test, pipeline_dl_v1.predict(X_test)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    print(f'------------------------------------------------------------')\n",
    "    print(f'{model_text} got an MCC of: {mcc}')\n",
    "    print(f'------------------------------------------------------------')\n",
    "    return mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-26T05:12:03.518135Z",
     "start_time": "2018-01-26T05:10:43.673584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 20)           20000     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 98, 64)            3904      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 40,801\n",
      "Trainable params: 40,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------\n",
      "Model V1 got an MCC of: 0.8890364403347154\n",
      "------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 50)           50000     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 98, 64)            9664      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 76,561\n",
      "Trainable params: 76,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------\n",
      "Model V2 got an MCC of: 0.9101838969331766\n",
      "------------------------------------------------------------\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 20)           20000     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 98, 256)           15616     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 101,665\n",
      "Trainable params: 101,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "------------------------------------------------------------\n",
      "Model V3 got an MCC of: 0.9057978267236877\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mcc_v1 = pipeline_dl(dl.get_cnn_model_v1, 'Model V1', X_train, y_train, X_test, y_test)\n",
    "mcc_v2 = pipeline_dl(dl.get_cnn_model_v2, 'Model V2', X_train, y_train, X_test, y_test)\n",
    "mcc_v3 = pipeline_dl(dl.get_cnn_model_v3, 'Model V3', X_train, y_train, X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results\n",
    "Here we can see that our best result was `0.9391` which is noticeably less than our MNB result of `0.9521`. This is quite incredible as MNB is quite a simple algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-26T05:12:03.526142Z",
     "start_time": "2018-01-26T05:12:03.520136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple: 0.9391490788432957\n",
      "MCC V1: 0.8890364403347154\n",
      "MCC V2: 0.9101838969331766\n",
      "MCC V3: 0.9057978267236877\n"
     ]
    }
   ],
   "source": [
    "print(f'Simple: {mcc_simp}')\n",
    "print(f'MCC V1: {mcc_v1}')\n",
    "print(f'MCC V2: {mcc_v2}')\n",
    "print(f'MCC V3: {mcc_v3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "I have left the architecture as the original author has written it. Deep Learning offers many ways to improve architecture, and it would be worthwhile finding an architecture that lends its self to solving our problem. I do believe that Deep Learning could find a solution stronger than our MNB results.\n",
    "\n",
    "Feature engineering is another avenue that could be explored more. Number of punctuation, number of capitalized letters, number if misspelled words, etc. These could all have good predicting power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
