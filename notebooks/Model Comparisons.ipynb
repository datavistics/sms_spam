{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context\n",
    "\n",
    "## Understanding the data\n",
    "This data is quite messy. Given that this is spam classification over other tasks like say topic classification, we need to adjust our approach accordingly. When we see odd punctuation, misspelled words, erratic patterns, odd capitializations, these are usually features and not noise.\n",
    "\n",
    "We also have a dataset of size 5572, this is rather small for advanced methods like Deep Learning, and we **might** result in an overfit model. Because of this, I will spend my time on more traditional methods, but I will look into it if I have time.\n",
    "\n",
    "## Goal\n",
    "The [paper](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/doceng11.pdf) that comes with the dataset, boasts \n",
    "\n",
    "| Classifier          | SC%    | BH%  | Acc%   | MCC   |\n",
    "|---------------------|--------|------|--------|-------|\n",
    "| SVM + tok1          | 83.10  | 0.18 | 97.64  | 0.893 |\n",
    "| Boosted NB + tok2   | 84.48  | 0.53 | 97.50  | 0.887 |\n",
    "| Boosted C4.5 + tok2 | 82.91  | 0.29 | 97.50  | 0.887 |\n",
    "\n",
    "## Data Status\n",
    "By the time the data gets to this notebook, it has:\n",
    "* Been downloaded, and unzipped\n",
    "* Read into a pandas dataframe\n",
    "\n",
    "# Approach\n",
    "There are a few factors at play here and we want to optimize each step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T21:04:29.155003Z",
     "start_time": "2018-01-23T21:04:28.319904Z"
    }
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import re\n",
    "from pprint import pprint\n",
    "from itertools import zip_longest\n",
    "import numpy as np\n",
    "\n",
    "project_dir = Path.cwd().parent\n",
    "sys.path.append(str(project_dir/'src'))\n",
    "\n",
    "# These are utilities that I created to reduce notebook clutter\n",
    "from make_dataframe import make_dataframe, master_data_handler\n",
    "import utilities as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition\n",
    "First we get our data, and then we encode it for use with our Classifiers. We should note our mapping for later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T21:04:29.185528Z",
     "start_time": "2018-01-23T21:04:29.157005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_data_handler()\n",
    "df = make_dataframe()\n",
    "df.label = df.label.map({'ham': 0, 'spam': 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its interesting to note that, with no machine learning we can get 86.6% Accuracy! This is a good warning that accuracy will probably not be a good metric for us. It also tells us that we have an imbalanced dataset. Depending on our classifier we need to handle this accordingly. \n",
    "\n",
    "SVM has a [class_weight parameter](http://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane_unbalanced.html#sphx-glr-auto-examples-svm-plot-separating-hyperplane-unbalanced-py) that allows us to compensate.\n",
    "\n",
    "Naive Bayes has a [complement class](http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf) structure that allows us to compensate. It has a corresponding function in sklearn - [ComplementNB](http://scikit-learn.org/dev/modules/generated/sklearn.naive_bayes.ComplementNB.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T21:04:29.391049Z",
     "start_time": "2018-01-23T21:04:29.187529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of ham to total:  0.8659368269921034\n"
     ]
    }
   ],
   "source": [
    "ratio = sum(df.label == 0)/len(df.label)\n",
    "print('Ratio of ham to total: ', ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "As said before, we need to choose a tokenizer that will capture the features we want: \n",
    "\n",
    "* Punctuation preservation\n",
    "* Case preservation\n",
    "* Full words in tokens\n",
    "\n",
    "There is research in spam classification [section 3.2](http://www.siefkes.net/ie/winnow-spam.pdf) with some good options. Unfortunately these are all in PCRE regex which python does not support fully (`\\p{Z}` among other atoms). But luckily they aren't too hard to convert, given our dataset (minimal control characters). \n",
    "\n",
    "I chose the simplified CRM114. Look how it handles an elipsis, we capture an extra feature of `'..'`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T21:04:29.547077Z",
     "start_time": "2018-01-23T21:04:29.393560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        SCRM114             Eager Token\n",
      "0       Go                  Go\n",
      "1       until               until\n",
      "2       jurong              jurong\n",
      "3       point,              point\n",
      "4       crazy.              \n",
      "5       .                   crazy\n",
      "6       Available           \n",
      "7       only                \n",
      "8       in                  Available\n",
      "9       bugis               only\n",
      "10      n                   in\n",
      "11      great               bugis\n",
      "12      world               n\n",
      "13      la                  great\n",
      "14      e                   world\n",
      "15      buffet.             la\n",
      "16      ..                  e\n",
      "17      Cine                buffet\n",
      "18      there               \n",
      "19      got                 \n",
      "20      amore               \n",
      "21      wat.                Cine\n",
      "22      ..                  there\n",
      "23      NULL                got\n",
      "24      NULL                amore\n",
      "25      NULL                wat\n",
      "26      NULL                \n",
      "27      NULL                \n",
      "28      NULL                \n"
     ]
    }
   ],
   "source": [
    "fmt = '%-8s%-20s%s'\n",
    "\n",
    "print(fmt % ('', 'SCRM114', 'Eager Token'))\n",
    "for i, (scrm, ets) in enumerate(zip_longest(ut.scrm114_tokenizer(df.text[0]), ut.eager_split_tokenizer(df.text[0]), fillvalue='NULL')):\n",
    "    print(fmt % (i, scrm, ets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "## Classification comparison metric\n",
    "As suggested in the dataset paper, Matthews Correlation Coefficient has been [researched](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5456046/) to be a metric that is good for unbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T21:04:29.775167Z",
     "start_time": "2018-01-23T21:04:29.548577Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, matthews_corrcoef, make_scorer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T21:04:29.897956Z",
     "start_time": "2018-01-23T21:04:29.776669Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.text, df.label, test_size=0.65, random_state=0)\n",
    "data_args = [X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Training\n",
    "Optimal linear kernal training [reference](https://www.svm-tutorial.com/2014/10/svm-linear-kernel-good-text-classification/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T21:04:33.938839Z",
     "start_time": "2018-01-23T21:04:29.899447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Best score:  0.9165769633559867\n",
      "Best params:  {'clf__class_weight': {0: 0.09}, 'vect__ngram_range': (1, 1), 'vect__tokenizer': <function eager_split_tokenizer at 0x000001C3F3376510>}\n",
      "Confusion Matrix:\n",
      " [[3131   14]\n",
      " [  57  420]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.98      1.00      0.99      3145\n",
      "       spam       0.97      0.88      0.92       477\n",
      "\n",
      "avg / total       0.98      0.98      0.98      3622\n",
      "\n",
      "Matthews Correlation Coefficient:  0.9122107742546972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    3.6s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline_svm = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "#     ('clf', SVC(kernel='linear')),\n",
    "    ('clf', LinearSVC()),\n",
    "])\n",
    "\n",
    "parameters_svm = {\n",
    "    'clf__class_weight': [{0: .09}],\n",
    "    'vect__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'vect__tokenizer': [ut.scrm114_tokenizer, ut.eager_split_tokenizer],\n",
    "}\n",
    "\n",
    "ut.grid_search_analysis(pipeline_svm, parameters_svm, *data_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T21:04:36.285646Z",
     "start_time": "2018-01-23T21:04:33.940843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Best score:  0.9138614511424891\n",
      "Best params:  {'clf__alpha': 1, 'vect__max_df': 1.2589254117941673, 'vect__ngram_range': (1, 1), 'vect__tokenizer': <function scrm114_tokenizer at 0x000001C3F31FE840>}\n",
      "Confusion Matrix:\n",
      " [[3140    5]\n",
      " [  44  433]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.99      1.00      0.99      3145\n",
      "       spam       0.99      0.91      0.95       477\n",
      "\n",
      "avg / total       0.99      0.99      0.99      3622\n",
      "\n",
      "Matthews Correlation Coefficient:  0.9398405227248262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:    2.1s finished\n"
     ]
    }
   ],
   "source": [
    "prior_0 = sum(y_train == 0) / len(y_train)\n",
    "prior_1 = sum(y_train == 1) / len(y_train)\n",
    "# print(prior_0, prior_1)\n",
    "\n",
    "pipeline_mnb = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB(class_prior=[prior_0, prior_1])),\n",
    "    #     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "parameters_mnb = {\n",
    "    'clf__alpha': [1],\n",
    "    'vect__tokenizer': [ut.scrm114_tokenizer, ut.eager_split_tokenizer],\n",
    "    'vect__ngram_range': [(1, 1)],\n",
    "    'vect__max_df': np.logspace(.1, 1, 6),\n",
    "}\n",
    "\n",
    "ut.grid_search_analysis(pipeline_mnb, parameters_mnb, *data_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T21:04:47.873676Z",
     "start_time": "2018-01-23T21:04:36.287138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "Best score:  0.7655684440532785\n",
      "Best params:  {'vect__max_df': 0.1, 'vect__ngram_range': (1, 1), 'vect__tokenizer': <function scrm114_tokenizer at 0x000001C3F31FE840>}\n",
      "Confusion Matrix:\n",
      " [[3133   12]\n",
      " [ 153  324]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.95      1.00      0.97      3145\n",
      "       spam       0.96      0.68      0.80       477\n",
      "\n",
      "avg / total       0.95      0.95      0.95      3622\n",
      "\n",
      "Matthews Correlation Coefficient:  0.7873108770282755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:   11.3s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline_rfc = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "parameters_rfc = {\n",
    "    'vect__tokenizer': [ut.scrm114_tokenizer, ut.eager_split_tokenizer],\n",
    "    'vect__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'vect__max_df': (.03, .1, .3),\n",
    "}\n",
    "\n",
    "ut.grid_search_analysis(pipeline_rfc, parameters_rfc, *data_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
