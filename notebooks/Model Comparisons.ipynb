{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context\n",
    "\n",
    "## Understanding the data\n",
    "This data is quite messy. Given that this is spam classification over other tasks like say topic classification, we need to adjust our approach accordingly. When we see odd punctuation, misspelled words, erratic patterns, odd capitializations, these are usually features and not noise.\n",
    "\n",
    "We also have a data set of size 5572, this is rather small for advanced methods like Deep Learning, and we **might** result in an overfit model. Because of this, I will spend my time on more traditional methods, but I will look into it if I have time.\n",
    "\n",
    "## Goal\n",
    "The [paper](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/doceng11.pdf) that comes with the data set, boasts \n",
    "\n",
    "| Classifier          | SC%    | BH%  | Acc%   | MCC   |\n",
    "|---------------------|--------|------|--------|-------|\n",
    "| SVM + tok1          | 83.10  | 0.18 | 97.64  | 0.893 |\n",
    "| Boosted NB + tok2   | 84.48  | 0.53 | 97.50  | 0.887 |\n",
    "| Boosted C4.5 + tok2 | 82.91  | 0.29 | 97.50  | 0.887 |\n",
    "\n",
    "## Data Status\n",
    "By the time the data gets to this notebook, it has:\n",
    "* Been downloaded, and unzipped\n",
    "* Read into a pandas dataframe\n",
    "\n",
    "# Approach\n",
    "There are a few factors at play here and we want to optimize each step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T19:31:21.039023Z",
     "start_time": "2018-01-23T19:31:20.153796Z"
    }
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "project_dir = Path.cwd().parent\n",
    "sys.path.append(str(project_dir/'src'))\n",
    "\n",
    "# These are utilities that I created to reduce notebook clutter\n",
    "from make_dataframe import make_dataframe, master_data_handler\n",
    "import utilities as ut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we get our data, and then we encode it for use with our Classifiers. We should note our mapping for later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T19:31:21.078047Z",
     "start_time": "2018-01-23T19:31:21.040515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_data_handler()\n",
    "df = make_dataframe()\n",
    "df.label = df.label.map({'ham': 0, 'spam': 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its interesting to note that, with no machine learning we can get 86.6% Accuracy! This is a good warning that accuracy will probably not be a good metric for us. It also tells us that we have an imbalanced data set. Depending on our classifier we need to handle this accordingly. \n",
    "\n",
    "SVM has a [class_weight parameter](http://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane_unbalanced.html#sphx-glr-auto-examples-svm-plot-separating-hyperplane-unbalanced-py) that allows us to compensate.\n",
    "\n",
    "Naive Bayes has a [complement class](http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf) structure that allows us to compensate. It has a corresponding function in sklearn - [ComplementNB](http://scikit-learn.org/dev/modules/generated/sklearn.naive_bayes.ComplementNB.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T19:31:21.221782Z",
     "start_time": "2018-01-23T19:31:21.083555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of ham to total:  0.8659368269921034\n"
     ]
    }
   ],
   "source": [
    "ratio = sum(df.label == 0)/len(df.label)\n",
    "print('Ratio of ham to total: ', ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said before, we need to choose a tokenizer that will capture the features we want: \n",
    "\n",
    "* Punctuation preservation\n",
    "* Case preservation\n",
    "* Full words in tokens\n",
    "\n",
    "There is research in spam classification [section 3.2](http://www.siefkes.net/ie/winnow-spam.pdf) with some good options. Unfortunately these are all in PCRE regex which python does not support fully (`\\p{Z}` among other atoms). But luckily they aren't too hard to convert, given our data set (minimal control characters). \n",
    "\n",
    "I chose the simplified CRM114. Look how it handles an elipsis, we capture an extra feature of `'..'`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T19:31:21.335461Z",
     "start_time": "2018-01-23T19:31:21.223283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "['Go',\n",
      " 'until',\n",
      " 'jurong',\n",
      " 'point,',\n",
      " 'crazy.',\n",
      " '.',\n",
      " 'Available',\n",
      " 'only',\n",
      " 'in',\n",
      " 'bugis',\n",
      " 'n',\n",
      " 'great',\n",
      " 'world',\n",
      " 'la',\n",
      " 'e',\n",
      " 'buffet.',\n",
      " '..',\n",
      " 'Cine',\n",
      " 'there',\n",
      " 'got',\n",
      " 'amore',\n",
      " 'wat.',\n",
      " '..']\n",
      "['Go',\n",
      " 'until',\n",
      " 'jurong',\n",
      " 'point',\n",
      " '',\n",
      " 'crazy',\n",
      " '',\n",
      " '',\n",
      " 'Available',\n",
      " 'only',\n",
      " 'in',\n",
      " 'bugis',\n",
      " 'n',\n",
      " 'great',\n",
      " 'world',\n",
      " 'la',\n",
      " 'e',\n",
      " 'buffet',\n",
      " '',\n",
      " '',\n",
      " '',\n",
      " 'Cine',\n",
      " 'there',\n",
      " 'got',\n",
      " 'amore',\n",
      " 'wat',\n",
      " '',\n",
      " '',\n",
      " '']\n"
     ]
    }
   ],
   "source": [
    "print(df.text[0])\n",
    "pprint(ut.scrm114_tokenizer(df.text[0]))\n",
    "pprint(ut.eager_split_tokenizer(df.text[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "## Classification comparison metric\n",
    "As suggested in the dataset paper, Matthews Correlation Coefficient has been [researched](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5456046/) to be a metric that is good for unbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T19:31:21.521060Z",
     "start_time": "2018-01-23T19:31:21.336961Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, matthews_corrcoef, make_scorer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T19:31:21.569259Z",
     "start_time": "2018-01-23T19:31:21.522556Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.text, df.label, test_size=0.65, random_state=0)\n",
    "data_args = [X_train, y_train, X_test, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T19:50:52.554423Z",
     "start_time": "2018-01-23T19:37:15.172912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 486 candidates, totalling 1458 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1458 out of 1458 | elapsed: 13.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.9050908933742281\n",
      "Best params:  {'clf__C': 0.7, 'clf__class_weight': {0: 0.16625987078248386}, 'clf__gamma': 0.002, 'vect__max_df': 0.1, 'vect__ngram_range': (1, 1), 'vect__tokenizer': <function eager_split_tokenizer at 0x0000025D93A05510>}\n",
      "Confusion Matrix:  [[3136    9]\n",
      " [  74  403]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.98      1.00      0.99      3145\n",
      "       spam       0.98      0.84      0.91       477\n",
      "\n",
      "avg / total       0.98      0.98      0.98      3622\n",
      "\n",
      "Matthews Correlation Coefficient:  0.8967709622737551\n"
     ]
    }
   ],
   "source": [
    "pipeline_svm = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', SVC(kernel='linear')),\n",
    "])\n",
    "\n",
    "parameters_svm = {\n",
    "    'clf__C': [.7, .08, .9],\n",
    "    'clf__class_weight': [{0: w * ratio} for w in [.192, .1925, .193]],\n",
    "    'clf__gamma': [0.002, 0.003, 0.004],\n",
    "    'vect__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'vect__max_df': (.03, .1, .3),\n",
    "    'vect__tokenizer': [ut.scrm114_tokenizer, ut.eager_split_tokenizer],\n",
    "}\n",
    "\n",
    "ut.grid_search_analysis(pipeline_svm, parameters_svm, *data_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T19:37:15.169916Z",
     "start_time": "2018-01-23T19:36:47.122368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8615384615384616 0.13846153846153847\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 162 out of 162 | elapsed:   27.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:  0.9366999215864544\n",
      "Best params:  {'clf__alpha': 0.17, 'vect__max_df': 0.4, 'vect__ngram_range': (1, 2), 'vect__tokenizer': <function scrm114_tokenizer at 0x0000025D9388E840>}\n",
      "Confusion Matrix:  [[3123   22]\n",
      " [  30  447]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.99      0.99      0.99      3145\n",
      "       spam       0.95      0.94      0.95       477\n",
      "\n",
      "avg / total       0.99      0.99      0.99      3622\n",
      "\n",
      "Matthews Correlation Coefficient:  0.9368201198559103\n"
     ]
    }
   ],
   "source": [
    "prior_0 = sum(y_train==0)/len(y_train)\n",
    "prior_1 = sum(y_train==1)/len(y_train)\n",
    "print(prior_0, prior_1)\n",
    "\n",
    "pipeline_mnb = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "#     ('clf', MultinomialNB(class_prior = [prior_0, prior_1])),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "parameters_mnb = {\n",
    "    'clf__alpha': [.17, .2, .23],\n",
    "    'vect__tokenizer': [ut.scrm114_tokenizer, ut.eager_split_tokenizer],\n",
    "    'vect__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'vect__max_df': (.4, .5, .6),}\n",
    "\n",
    "ut.grid_search_analysis(pipeline_mnb, parameters_mnb, *data_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T19:53:33.924448Z",
     "start_time": "2018-01-23T19:53:22.849854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "Best score:  0.7628836104451964\n",
      "Best params:  {'vect__max_df': 0.03, 'vect__ngram_range': (1, 1), 'vect__tokenizer': <function scrm114_tokenizer at 0x0000025D9388E840>}\n",
      "Confusion Matrix:  [[3144    1]\n",
      " [ 165  312]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.95      1.00      0.97      3145\n",
      "       spam       1.00      0.65      0.79       477\n",
      "\n",
      "avg / total       0.96      0.95      0.95      3622\n",
      "\n",
      "Matthews Correlation Coefficient:  0.7868174926237372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:   10.8s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline_rfc = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "parameters_rfc = {\n",
    "    'vect__tokenizer': [ut.scrm114_tokenizer, ut.eager_split_tokenizer],\n",
    "    'vect__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'vect__max_df': (.03, .1, .3),}\n",
    "\n",
    "ut.grid_search_analysis(pipeline_rfc, parameters_rfc, *data_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
